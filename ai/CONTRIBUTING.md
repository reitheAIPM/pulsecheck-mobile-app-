# Contributing to PulseCheck - AI-Only Development Environment

**Purpose**: Master directory and guidelines for **AI-ONLY** development and debugging  
**Last Updated**: June 27, 2025  
**Critical Reality**: âŒ **NOT PRODUCTION READY** - Failed initial beta launch with bugs

---

## ðŸš¨ **CRITICAL: AI-ONLY DEVELOPMENT REALITY**

### **ðŸ¤– PRIMARY CONSTRAINT: CURSOR AI IS SOLE DEVELOPER**
**â— ABSOLUTE REQUIREMENT**: All systems must be designed for **AI-only operation**

- **NO HUMAN DEBUGGING ASSISTANCE**: AI must diagnose and fix all issues independently
- **MAXIMUM AI EFFICIENCY**: All tools optimized for minimal tool calls
- **COMPLETE CONTEXT PROVISION**: Every debugging scenario must provide full context
- **ERROR RECOVERY**: AI must understand and fix errors without human interpretation
- **DOCUMENTATION**: All notes, tools, and guides written specifically for AI understanding

### **ðŸŽ¯ PRIMARY GOAL: AI AUTONOMOUS PROBLEM SOLVING**
```
When something fails â†’ AI gets complete context â†’ AI fixes issue â†’ AI validates fix
```

### **âš¡ SECONDARY GOAL: MINIMAL TOOL CALLS**
- **1-3 calls maximum** for issue diagnosis
- **Single file references** provide complete context
- **Parallel tool calls** when gathering information
- **Comprehensive endpoints** eliminate investigation loops

---

## ðŸš¨ **CRITICAL: PRODUCTION READINESS REALITY CHECK**

### **âŒ CURRENT STATUS: FAILED BETA LAUNCH**
- **Beta Testers**: 3-6 users experienced constant bugs
- **Launch Result**: Failed due to overlooked issues
- **User Experience**: Poor - bugs disrupted core functionality
- **Production Readiness**: âŒ **NOT READY** despite previous optimistic assessments

### **ðŸŽ¯ USER EXPERIENCE IS PRIMARY PRIORITY**
- **User experience supersedes all technical considerations**
- **Bug-free operation is mandatory before any launch**
- **Beta tester feedback must be addressed comprehensively**
- **Launch readiness requires thorough testing and validation**

### **ðŸ“Š HONEST ASSESSMENT REQUIREMENTS**
- **NO SUGARCOATING**: Distinguish between "working" vs "tested"
- **REALISTIC CONFIDENCE LEVELS**: Based on actual user validation
- **COMPREHENSIVE TESTING**: End-to-end user flows must be validated
- **ERROR SCENARIOS**: All failure modes must be tested and handled
- **LAUNCH READINESS**: See `LAUNCH-READINESS-ASSESSMENT.md` for comprehensive criteria

---

## ðŸš¨ **CRITICAL: ENVIRONMENT STRATEGY**

### **CURRENT: PRODUCTION-ONLY DEVELOPMENT**
**We are currently using PRODUCTION infrastructure for all development:**

- **Frontend**: Vercel deployment (spark-realm) - **LIVE PRODUCTION DATA**
- **Backend**: Railway deployment (FastAPI) - **LIVE PRODUCTION API**  
- **Database**: Supabase production instance - **LIVE USER DATA**
- **AI Services**: OpenAI production API - **LIVE PROCESSING & COSTS**
- **Environment**: Windows PowerShell - **PRODUCTION DEBUGGING ONLY**

### **FUTURE: DEVELOPMENT BRANCH STRATEGY**
**When we create development branches (NOT YET):**
- **GitHub**: dev branch â†’ triggers Railway/Vercel dev deployments
- **Railway**: Separate dev environment with mock data
- **Vercel**: Separate dev preview with test configurations
- **Database**: Separate dev Supabase project or staging tables
- **Testing**: Mock data and local testing allowed

### **âš ï¸ UNTIL DEV BRANCHES: NO LOCAL/MOCK DATA**
- **NO localhost references** in any code
- **NO mock data** in any debugging tools
- **NO local development** environment setup
- **ALL debugging** uses production endpoints
- **ALL testing** affects live user experience

---

## ðŸš¨ **PRODUCTION ENVIRONMENT OVERVIEW**

### **Current Architecture (PRODUCTION)**
PulseCheck operates in a **full production environment** with the following stack:

- **Frontend**: Vercel deployment (spark-realm) - **LIVE PRODUCTION**
- **Backend**: Railway deployment (FastAPI) - **LIVE PRODUCTION**  
- **Database**: Supabase production instance - **LIVE DATA**
- **AI Services**: OpenAI production API - **LIVE PROCESSING**
- **Authentication**: Supabase Auth with RLS security - **LIVE USERS**
- **File Storage**: Supabase Storage with user isolation - **LIVE FILES**
- **Real-time**: Supabase Realtime with user-scoped subscriptions - **LIVE UPDATES**

### **âš ï¸ CRITICAL: No Local Development**
- **NO localhost references** - everything uses production URLs
- **NO mock data** - all data comes from live Supabase production
- **NO development fallbacks** - ENVIRONMENT=production enforced
- **NO fake responses** - AI uses real OpenAI API or fallback notifications

---

## ðŸ”§ **AI DEBUGGING SYSTEM FOR CLAUDE**

### **ðŸŽ¯ PURPOSE: EFFICIENT PRODUCTION DEBUGGING**
This system enables Claude to debug the live production platform with minimal tool calls and maximum insight.

### **ðŸ“‹ COMPLETE SYSTEM DOCUMENTATION**
**ðŸ”— [AI-DEBUGGING-SYSTEM.md](AI-DEBUGGING-SYSTEM.md)** - **READ THIS FIRST FOR ALL DEBUGGING**

Our comprehensive debugging system includes:
- **Sentry Error Tracking**: Real-time error capture with AI context
- **Observability Middleware**: Request correlation and performance tracking  
- **OpenAI Observability**: AI-specific monitoring and cost tracking
- **Debug Endpoints**: Production-safe investigation routes
- **False Positive Prevention**: Clear warnings and empty data handling

### **ðŸš¨ FALSE POSITIVE PREVENTION**
Our debug system is designed to **prevent false positives** that could mislead AI debugging:

- **Production-Safe Data**: No mock data that could indicate false "healthy" status
- **Clear Warnings**: All endpoints explicitly warn when real data is unavailable  
- **Empty Result Identification**: Empty arrays are flagged as "not representative of system health"
- **Middleware Status**: Clear indicators when debug middleware isn't capturing real traffic

**âš ï¸ CRITICAL**: Always read [AI-DEBUGGING-SYSTEM.md](AI-DEBUGGING-SYSTEM.md) to understand the complete system structure before debugging.

---

## ðŸ¤– **CLAUDE DEBUGGING PROTOCOL**

### **ðŸš¨ CRITICAL: PRODUCTION TECH STACK CONTEXT**
**â— ALWAYS REMEMBER**: We are running **PRODUCTION INFRASTRUCTURE**:
- **Frontend**: Vercel deployment (spark-realm) - **NOT localhost**
- **Backend**: Railway deployment (FastAPI) - **NOT local development**  
- **Database**: Supabase production instance - **NOT local database**
- **AI Services**: OpenAI production API - **NOT mock responses**
- **Environment**: Windows PowerShell - **NOT Unix/Linux**

### **ðŸš¨ CRITICAL: PowerShell Compatibility Requirements**
**â— ALWAYS Use curl.exe in PowerShell (NOT curl)**
```powershell
# âœ… CORRECT - Use curl.exe for PowerShell compatibility
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary"

# âŒ WRONG - Don't use curl (causes PowerShell issues)
curl -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary"
```

### **âš ï¸ CRITICAL: PowerShell Command Limitations**
**â— MAJOR CONSTRAINT: Long commands cause terminal hangs/crashes**

**FAILED COMMANDS - DO NOT USE:**
- **Long commands (>500 characters)**: Cause PowerShell to freeze indefinitely
- **Complex inline JSON**: Multi-line JSON in command line causes parser errors  
- **Token separators**: `&&` not supported, causes parsing failures
- **Python -c with long strings**: Extremely long single-line Python commands hang terminal

**âœ… EFFICIENT ALTERNATIVES:**
```powershell
# âœ… SHORT commands with timeouts
curl.exe --max-time 5 "https://api-url/endpoint"

# âœ… SIMPLE data - avoid complex JSON
curl.exe -d "{'simple':'data'}" -H "Content-Type: application/json"

# âœ… CREATE .ps1 scripts for complex operations
# Write to file, then execute

# âœ… SEPARATE commands instead of &&
curl.exe -s "url1"
curl.exe -s "url2"
```

**Why this matters:**
- PowerShell has its own `curl` alias that conflicts with standard curl behavior
- Using `curl.exe` directly ensures consistent results
- Prevents PowerShell parsing issues and command failures
- **Long commands literally freeze the terminal requiring manual intervention**

### **ðŸ” STEP 1: INITIAL SYSTEM ASSESSMENT**
**Use these endpoints first to understand system state:**

```bash
# Primary health check (ALWAYS START HERE)
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/health

# Production debug overview (CRITICAL CONTEXT)
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary

# OpenAI system status (AI-SPECIFIC)
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/openai/debug/summary
```

**âš ï¸ INTERPRET RESULTS CAREFULLY:**
- **Empty data** = Debug middleware not capturing real traffic (NOT healthy system)
- **"production_warning" present** = No real performance data available  
- **"middleware_status": "not_available"** = Limited debugging capabilities

### **ðŸ” STEP 2: TARGETED INVESTIGATION**
**Based on issue type, use specific endpoints:**

#### **ðŸš¨ Error Debugging**
```bash
# Error pattern analysis
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=errors&limit=20"

# Claude-optimized context
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/claude/context?issue_type=error&time_window=30"
```

#### **âš¡ Performance Issues**
```bash
# Slow request analysis  
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=slow&min_time_ms=1000"

# Performance trends
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/performance/analysis"
```

#### **ðŸ” Authentication Problems**
```bash
# Auth pattern validation
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/claude/context?issue_type=auth"

# RLS security audit
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/configuration-audit"
```

#### **ðŸ¤– AI Service Issues**
```bash
# OpenAI connectivity & cost tracking
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/openai/debug/test-connection"

# AI persona functionality
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/openai/debug/test-personas"

# Error pattern analysis
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/openai/debug/error-patterns"
```

### **ðŸ” STEP 3: PREDICTIVE ANALYSIS**
**Use AI-enhanced endpoints for deeper insights:**

```bash
# Comprehensive system analysis
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/ai-insights/comprehensive"

# Failure point prediction
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/failure-points/analysis"

# Risk assessment
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/risk-analysis/current?time_window=60"
```

---

## ðŸŽ¯ **EFFICIENT DEBUGGING GUIDELINES FOR CLAUDE**

### **âœ… OPTIMAL DEBUGGING APPROACH**

#### **1. PARALLEL TOOL CALLS**
**Always use multiple debug endpoints simultaneously:**
```
// Example: Investigate performance issue
GET /api/v1/health (basic status)
GET /api/v1/debug/summary (system overview)  
GET /api/v1/debug/requests?filter_type=slow (performance data)
GET /api/v1/debug/claude/context?issue_type=performance (AI analysis)
```

#### **2. CONTEXT-AWARE INTERPRETATION**
**Always check for these key indicators:**
- `middleware_status`: "not_available" = Limited real data
- `production_warning`: Present = Interpret empty results as "unknown" not "healthy"
- `false_positive_risk`: "HIGH" = Don't assume empty results mean no issues

#### **3. ESCALATION TRIGGERS**
**Escalate to user when:**
- All debug endpoints return empty data AND no production_warning
- Authentication errors prevent access to debug endpoints
- Multiple 500 errors from debug system itself
- OpenAI API showing authentication failures

### **âŒ AVOID THESE DEBUGGING MISTAKES**

1. **DON'T assume empty results = healthy system**
2. **DON'T use localhost URLs for testing**
3. **DON'T interpret mock data as real system state**
4. **DON'T make sequential debug calls when parallel calls work**
5. **DON'T skip checking production_warning flags**

---

## ðŸ”§ **DEBUGGING IN PRODUCTION**
Since we're in production, use production-safe debugging methods:

#### **âœ… SAFE PRODUCTION DEBUGGING**
```bash
# Use production debug endpoints
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/health
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/openai/debug/summary
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary
```

#### **âŒ AVOID IN PRODUCTION**
- Local server testing
- Mock data insertion  
- Development mode flags
- Localhost API calls
- **False positive risks**: Empty debug results interpreted as "healthy"
- **Misleading mock data**: Any endpoint returning fake successful data

**ðŸš¨ CRITICAL WARNING**: Always check for `production_warning` in debug responses. Empty results without warnings may indicate debug middleware not capturing real traffic.

---

## ðŸŒ **ENVIRONMENT CONFIGURATION STATUS**

### **âœ… CONFIRMED PRODUCTION SETUP**

#### **Backend (.env) - VERIFIED âœ…**
```bash
ENVIRONMENT=production
SUPABASE_URL=https://qwpwlubxhtuzvmvajjjr.supabase.co  
SUPABASE_ANON_KEY=[PRODUCTION_KEY]
SUPABASE_SERVICE_KEY=[ADMIN_KEY]
OPENAI_API_KEY=[LIVE_API_KEY]
```

#### **Frontend (.env) - VERIFIED âœ…**  
```bash
REACT_APP_API_URL=https://pulsecheck-mobile-app-production.up.railway.app
REACT_APP_SUPABASE_URL=https://qwpwlubxhtuzvmvajjjr.supabase.co
REACT_APP_SUPABASE_ANON_KEY=[PUBLIC_KEY]
```

#### **âš ï¸ AI ASSISTANT PROTOCOL**
- **DO NOT ask about missing .env files** - Both backend and frontend .env files exist and are properly configured
- **DO NOT suggest creating .env files** - They are already set up for production
- **DO NOT ask for environment variable values** - All required variables are configured

---

## ðŸš€ **PRODUCTION READINESS STATUS**

### **âœ… SYSTEMS OPERATIONAL**
- **Authentication & Security**: RLS properly configured
- **AI Services**: 4 personas with OpenAI observability
- **Database**: Supabase production instance connected
- **Real-time**: User-scoped subscriptions active
- **File Storage**: RLS-secured with user isolation
- **Error Handling**: Comprehensive debugging system
- **Performance Monitoring**: OpenAI cost tracking active

### **ðŸ”® FUTURE DEVELOPMENT ENVIRONMENT**
When development branches are created:
- **GitHub**: dev branch â†’ triggers Railway/Vercel dev deployments
- **Railway**: Separate dev environment with mock data
- **Vercel**: Separate dev preview with test configurations
- **Database**: Separate dev Supabase project or staging tables

---

## ðŸ“Š **DEBUGGING DECISION TREE FOR CLAUDE**

### **START HERE: Health Check**
```
1. GET /health â†’ 200 OK?
   â”œâ”€ YES: System operational, proceed to specific debugging
   â””â”€ NO: Critical system failure, check infrastructure
```

### **ðŸŽ¯ SINGLE COMMAND VERIFICATION**
**Consolidated system verification (replaces 4 separate commands):**
```powershell
# Once deployed: All-in-one system check (COMING SOON)
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/database/full-system-check"

# Current working verification commands:
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/database/environment"
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/database/comprehensive-status"
```

**What the consolidated check provides:**
- âœ… Environment variables (SUPABASE_SERVICE_ROLE_KEY status)
- âœ… Database client creation testing
- âœ… Database query functionality validation
- âœ… Auth methods availability check
- âœ… Overall status assessment with actionable recommendations
- âœ… Response time monitoring

**Efficiency Gain:** Reduces verification from 4 curl commands to 1

### **ISSUE-SPECIFIC DEBUGGING**

```
2. Issue Type Detection:
   â”œâ”€ AUTHENTICATION: Use /debug/claude/context?issue_type=auth
   â”œâ”€ PERFORMANCE: Use /debug/requests?filter_type=slow  
   â”œâ”€ AI_SERVICES: Use /openai/debug/test-personas
   â”œâ”€ ERRORS: Use /debug/requests?filter_type=errors
   â””â”€ GENERAL: Use /debug/summary + /debug/ai-insights/comprehensive
```

### **INTERPRETATION GUIDELINES**

```
3. Result Analysis:
   â”œâ”€ Empty data + production_warning: Debug middleware not capturing traffic
   â”œâ”€ Empty data + NO warning: Potential system issue OR healthy system
   â”œâ”€ Error patterns found: Analyze with /debug/claude/context
   â””â”€ Performance issues: Check /debug/failure-points/analysis
```

---

## ðŸš¨ **RAILWAY ENVIRONMENT SETUP**

### **Critical Environment Variables**
Our production deployment requires specific environment variables in Railway:

**ðŸ”§ Quick Environment Diagnosis:**
```powershell
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/database/environment"
```

**Required Variables:**
- âœ… `SUPABASE_URL` - Database connection endpoint
- âœ… `SUPABASE_ANON_KEY` - Public authentication key  
- âœ… `SUPABASE_SERVICE_ROLE_KEY` - Backend operations key (**Critical for auth signup/database operations**)
- âš ï¸ `DB_PASSWORD` - Database password (optional but recommended)

### **Adding Missing Variables to Railway**
1. Go to [Railway Dashboard](https://railway.app/) 
2. Select your PulseCheck project
3. Navigate to **Variables** tab
4. Click **Add Variable**
5. Add missing variable with its value
6. Wait 2-3 minutes for automatic redeploy
7. Verify with environment check endpoint

### **ðŸ”— Detailed Setup Documentation**
For comprehensive setup instructions: **[ai/RAILWAY_ENVIRONMENT_SETUP.md](RAILWAY_ENVIRONMENT_SETUP.md)**

**Contains:**
- Step-by-step Railway configuration
- Verification commands with expected results  
- Troubleshooting guide for deployment issues
- PowerShell-compatible curl.exe commands
- Before/after environment comparisons

---

## ðŸŽ¯ **EFFICIENT DEBUGGING GUIDELINES FOR CLAUDE**

### **âœ… OPTIMAL DEBUGGING APPROACH**

#### **1. PARALLEL TOOL CALLS**
**Always use multiple debug endpoints simultaneously:**
```
// Example: Investigate performance issue
GET /api/v1/health (basic status)
GET /api/v1/debug/summary (system overview)  
GET /api/v1/debug/requests?filter_type=slow (performance data)
GET /api/v1/debug/claude/context?issue_type=performance (AI analysis)
```

#### **2. CONTEXT-AWARE INTERPRETATION**
**Always check for these key indicators:**
- `middleware_status`: "not_available" = Limited real data
- `production_warning`: Present = Interpret empty results as "unknown" not "healthy"
- `false_positive_risk`: "HIGH" = Don't assume empty results mean no issues

#### **3. ESCALATION TRIGGERS**
**Escalate to user when:**
- All debug endpoints return empty data AND no production_warning
- Authentication errors prevent access to debug endpoints
- Multiple 500 errors from debug system itself
- OpenAI API showing authentication failures

### **âŒ AVOID THESE DEBUGGING MISTAKES**

1. **DON'T assume empty results = healthy system**
2. **DON'T use localhost URLs for testing**
3. **DON'T interpret mock data as real system state**
4. **DON'T make sequential debug calls when parallel calls work**
5. **DON'T skip checking production_warning flags**

---

## ðŸ”§ **DEBUGGING IN PRODUCTION**
Since we're in production, use production-safe debugging methods:

#### **âœ… SAFE PRODUCTION DEBUGGING**
```bash
# Use production debug endpoints
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/health
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/openai/debug/summary
curl.exe -s https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary
```

#### **âŒ AVOID IN PRODUCTION**
- Local server testing
- Mock data insertion  
- Development mode flags
- Localhost API calls
- **False positive risks**: Empty debug results interpreted as "healthy"
- **Misleading mock data**: Any endpoint returning fake successful data

**ðŸš¨ CRITICAL WARNING**: Always check for `production_warning` in debug responses. Empty results without warnings may indicate debug middleware not capturing real traffic.

---

## ðŸŽ‰ **MAJOR SUCCESS: AI-POWERED DEBUGGING SYSTEM OPERATIONAL**

### **ðŸ† BREAKTHROUGH ACHIEVED: Complete Infrastructure Issue Resolution**

**Date**: January 30, 2025  
**Achievement**: Successfully resolved critical routing issue affecting ALL `/api/v1/*` endpoints  
**Method**: AI-powered systematic debugging with comprehensive testing and log analysis  
**Result**: **All 7 routers now fully operational** with AI debugging system ready

### **ðŸŽ¯ PRIMARY DEBUGGING APPROACH - PROVEN WORKING**

**CONFIRMED**: The debugging middleware system successfully provides comprehensive data in 1-3 tool calls instead of 10-15, as demonstrated by our recent infrastructure resolution.

#### **Step 1: Quick System Health Check**
```bash
# Single command gives you complete system overview
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary
```

**This ONE call provides:**
- Recent requests with errors, timing, and performance scores
- Database operation statistics and bottlenecks  
- Error patterns and frequencies
- Performance analysis with recommendations
- System health indicators

#### **Step 2: Deep Dive (If Issues Found)**
```bash
# Get specific request details with full context
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests/{request_id}

# Or filter for specific issue types
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=errors
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=slow
```

**This provides:**
- Complete request/response cycle data
- All database operations for that request
- Performance metrics and scoring
- Error context and timing
- User authentication status

#### **Step 3: Performance Analysis**
```bash
# Get performance grades and recommendations
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/performance/analysis
```

### **ðŸš¨ WHEN TO USE OLD vs NEW DEBUGGING**

#### **âœ… USE MIDDLEWARE DEBUG SYSTEM FOR:**
- User reports errors, slow performance, or functional issues
- Authentication problems  
- Database performance issues
- CORS errors
- API endpoint problems
- Response time investigations
- Error pattern analysis

#### **âŒ ONLY USE MANUAL INVESTIGATION FOR:**
- Initial project setup
- Configuration file creation
- Environment variable setup (first time)
- Code architecture decisions
- Feature development planning

### **ðŸ“‹ AI DEBUGGING WORKFLOW - PROVEN SUCCESSFUL**

#### **For ANY User-Reported Issue - VALIDATED METHODOLOGY:**

**Step 1** (1 tool call): Check middleware debug summary âœ… **WORKING**
```bash
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary"
```

**Step 2** (1 tool call): If issues found, get specific details âœ… **WORKING**
```bash  
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=errors"
```

**Step 3** (Optional): Deep dive into specific problematic request âœ… **WORKING**
```bash
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests/{specific_request_id}"
```

## **DEPLOYMENT & TESTING LESSONS LEARNED**

### **âœ… WHAT WORKS (Use These Approaches):**

**Commands & Tools:**
- `curl.exe` - Always use .exe extension on Windows
- `Invoke-RestMethod` - Reliable for PowerShell HTTP requests
- `git add`, `git commit`, `git push` - Standard git workflow works perfectly
- Railway deployment via git push - Automatic detection and rebuilding
- FastAPI with performance optimizations - Achieved 99.5% improvement

**Performance Optimizations (Proven Effective):**
- GZip compression middleware - Massive response time improvements
- Database connection pooling - Infrastructure optimization
- Horizontal scaling with Railway - 2 replicas working
- Resource limits (2 vCPU, 4GB RAM) - Stable performance
- Health endpoint monitoring - Real-time performance tracking

**Error Resolution Patterns:**
- Import errors: Add missing imports to requirements.txt immediately
- Dependency conflicts: Pin specific versions (e.g., gotrue==2.8.1)
- Supabase client: Remove unsupported options parameters

### **âŒ WHAT DOESN'T WORK (Avoid These):**

**Commands & Tools:**
- `curl` without .exe - Fails on Windows PowerShell
- Complex PowerShell one-liners - Console buffer issues, unreliable
- Long PowerShell commands - Cause display errors and timeouts
- Multiple sequential curl calls - Leads to hanging

**Testing Approaches:**
- Running multiple separate test scripts - Inefficient, fragmented results
- Testing without timeout parameters - Causes indefinite hanging
- Complex PowerShell syntax in single commands - Parser errors

**Database Connection Issues (Still Investigating):**
- Supabase client with options parameter - Not supported in current version
- Long-running database operations without proper timeout handling
- Missing psycopg2 dependency - Causes SQLite fallback

### **ðŸ”§ RELIABLE PATTERNS TO FOLLOW:**

1. **Always use `curl.exe` on Windows**
2. **Keep PowerShell commands simple and short**
3. **Use timeouts on all HTTP requests (10-30 seconds)**
4. **Pin all dependency versions in requirements.txt**
5. **Test infrastructure endpoints first, then database endpoints**
6. **Use git workflow for all deployments - Railway auto-detects**
7. **Performance optimizations work - connection pooling, compression, scaling**

### **ðŸš¨ CURRENT KNOWN ISSUES:**

**RESOLVED:**
- âœ… GZipMiddleware import error - Fixed with proper import
- âœ… psycopg2 missing dependency - Added psycopg2-binary==2.9.9
- âœ… Supabase client options - Removed unsupported parameters
- âœ… Performance (27sâ†’126ms) - Fixed with optimization stack

**ACTIVE INVESTIGATION:**
- âŒ Database endpoints timing out after 10-15 seconds
- âŒ Version endpoint returning 404 (partial deployment)
- âŒ Auth/Journal operations hanging despite infrastructure improvements

**DEPLOYMENT DISCREPANCY RESOLVED:**
- âœ… **RESOLVED 2025-06-27**: Railway deployment discrepancy fixed with force push
- âœ… Complete project synchronization completed to ensure Railway has latest code
- âœ… No longer running stale cached builds - all commits now deploy properly
- **NOTE**: If database endpoints still hang after this sync, it's a true connection issue, not old code

---

## ðŸ—„ï¸ **SUPABASE DATABASE MIGRATIONS**

### **Supabase CLI Setup and Migration Process**

Our project uses Supabase CLI for database schema management. Here's the complete process:

**âœ… CLI Available:** `npx supabase --version` (version 2.26.9 confirmed)

### **ðŸ”§ MIGRATION WORKFLOW**

#### **1. Check Project Status**
```powershell
# List available projects
npx supabase projects list

# Check current link status
npx supabase status
```

#### **2. Link to Remote Project**
```powershell
# Link to production project (use your actual project-ref)
npx supabase link --project-ref qwpwlubxhtuzvmvajjjr --password "YOUR_DB_PASSWORD"
```

#### **3. Check Migration Status**
```powershell
# See which migrations are applied locally vs remotely
npx supabase migration list
```

#### **4. Apply Migrations**
```powershell
# Push all pending migrations (preferred)
npx supabase db push --include-all

# Push specific migration
npx supabase db push

# Dry run to preview changes
npx supabase db push --dry-run
```

### **ðŸš¨ COMMON MIGRATION ISSUES & SOLUTIONS**

#### **Issue: "Found local migration files to be inserted before the last migration"**
**Solution:** Use `--include-all` flag
```powershell
npx supabase db push --include-all
```

#### **Issue: "functions in index predicate must be marked IMMUTABLE"**
**Cause:** PostgreSQL doesn't allow volatile functions in index predicates  
**Solution:** Remove problematic indexes or use static timestamps instead of `NOW()`

#### **Issue: "migration history does not match local files"**
**Solution:** Repair migration status
```powershell
npx supabase migration repair --status applied MIGRATION_ID
```

### **ðŸ“‹ MANUAL MIGRATION (Supabase Dashboard)**

When CLI migration fails, use Supabase Dashboard:

1. Go to [Supabase Dashboard](https://supabase.com/dashboard)
2. Select your project  
3. Navigate to **SQL Editor**
4. Create new query
5. Paste migration SQL
6. Click **Run**

### **ðŸŽ¯ ESSENTIAL PROFILES TABLE MIGRATION**

**Issue:** Missing `profiles` table causes database queries to fail  
**Error:** `relation "public.profiles" does not exist`

**Quick Fix SQL (run in Supabase Dashboard):**
```sql
-- Create a table for public profiles
CREATE TABLE IF NOT EXISTS public.profiles (
  id uuid references auth.users not null primary key,
  created_at timestamp with time zone DEFAULT NOW(),
  updated_at timestamp with time zone DEFAULT NOW(),
  email text,
  full_name text,
  avatar_url text,
  username text unique,
  
  -- PulseCheck specific fields
  wellness_score integer DEFAULT 50 CHECK (wellness_score >= 0 AND wellness_score <= 100),
  streak_days integer DEFAULT 0,
  total_entries integer DEFAULT 0,
  last_checkin timestamp with time zone,
  ai_persona_preference text DEFAULT 'balanced',
  notification_preferences jsonb DEFAULT '{"daily_reminder": true, "weekly_summary": true}',
  
  constraint username_length check (char_length(username) >= 3)
);

-- Set up Row Level Security (RLS)
ALTER TABLE public.profiles ENABLE ROW LEVEL SECURITY;

-- RLS Policies for profiles
CREATE POLICY "Public profiles are viewable by everyone" ON public.profiles
  FOR SELECT USING (true);

CREATE POLICY "Users can insert their own profile" ON public.profiles
  FOR INSERT WITH CHECK (auth.uid() = id);

CREATE POLICY "Users can update their own profile" ON public.profiles
  FOR UPDATE USING (auth.uid() = id);

-- Trigger to automatically create profile when user signs up
CREATE OR REPLACE FUNCTION public.handle_new_user()
RETURNS trigger AS $$
BEGIN
  INSERT INTO public.profiles (id, email, full_name, avatar_url)
  VALUES (
    NEW.id, 
    NEW.email,
    NEW.raw_user_meta_data->>'full_name', 
    NEW.raw_user_meta_data->>'avatar_url'
  );
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Drop trigger if exists and recreate
DROP TRIGGER IF EXISTS on_auth_user_created ON auth.users;
CREATE TRIGGER on_auth_user_created
  AFTER INSERT ON auth.users
  FOR EACH ROW EXECUTE FUNCTION public.handle_new_user();

-- Create updated_at trigger
CREATE OR REPLACE FUNCTION public.handle_updated_at()
RETURNS trigger AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER profiles_updated_at
  BEFORE UPDATE ON public.profiles
  FOR EACH ROW EXECUTE FUNCTION public.handle_updated_at();
```

### **âœ… VERIFY MIGRATION SUCCESS**

After applying the profiles table migration:

```powershell
# Test database connectivity
curl.exe -s "https://pulsecheck-mobile-app-production.up.railway.app/api/v1/database/comprehensive-status"
```

**Expected Result:**
```json
"database_query": "âœ… SUCCESS"
"overall_status": "âœ… HEALTHY"
```

---