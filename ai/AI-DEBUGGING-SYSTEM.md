# ü§ñ AI-Powered Debugging System

**Status**: ‚úÖ **ACTIVE** (January 30, 2025)  
**Purpose**: Comprehensive middleware-based debugging for PulseCheck  
**Strategy**: Reduce 10-15 tool calls to 1-3 calls using structured debugging data

---

## üéØ **SYSTEM OVERVIEW**

This debugging system uses **middleware-based data capture** to eliminate manual log parsing and investigation. Instead of diving into Railway logs, environment variables, and code every time an issue occurs, you now get comprehensive debugging data through structured API endpoints.

### **üîÑ PARADIGM SHIFT**

**‚ùå OLD APPROACH:**
- User reports issue ‚Üí Check Railway logs ‚Üí Test endpoints manually ‚Üí Verify CORS ‚Üí Check environment vars ‚Üí Read code ‚Üí 10-15 tool calls

**‚úÖ NEW APPROACH:**  
- User reports issue ‚Üí GET /debug/summary ‚Üí Instant comprehensive data ‚Üí Apply fixes ‚Üí 1-3 tool calls

---

## üöÄ **QUICK START - USE THESE FIRST**

### **üîç Step 1: System Health Overview**
```bash
# Single command for complete system status
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/summary
```

**Returns in ONE call:**
- Recent requests with performance scores
- Error requests with full context  
- Database operation statistics
- Performance analysis with grades
- Automatic recommendations

### **üîç Step 2: Error Investigation** 
```bash
# Get all recent errors with context
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=errors

# Get slow requests
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests?filter_type=slow
```

### **üîç Step 3: Specific Request Deep Dive**
```bash
# Complete request/response/database analysis for specific request
curl https://pulsecheck-mobile-app-production.up.railway.app/api/v1/debug/requests/{request_id}
```

---

## üì° **MIDDLEWARE DEBUG API ENDPOINTS**

### **1. Debug Summary** - `/api/v1/debug/summary`
**Purpose**: Complete system overview in one call  
**Method**: GET  
**Replaces**: Railway logs + manual endpoint testing + CORS checking

```json
{
  "status": "success",
  "timestamp": "2025-01-30T10:30:00Z",
  "debug_summary": {
    "recent_requests": [
      {
        "request_id": "uuid-123",
        "method": "POST",
        "url": "/api/v1/journal/entries",
        "status_code": 500,
        "response_time_ms": 2500,
        "db_operations": 8,
        "has_errors": true,
        "performance_score": "poor"
      }
    ],
    "error_requests": [/* Filtered error requests */],
    "slow_requests": [/* Performance issues */],
    "database_stats": {
      "total_operations": 150,
      "average_time_ms": 120,
      "error_rate": 0.02,
      "by_table": {
        "journal_entries": {"count": 45, "avg_time": 120.5},
        "users": {"count": 12, "avg_time": 50.2}
      },
      "recommendations": [
        "Consider indexing journal_entries.user_id - 45 queries averaging 120ms"
      ]
    }
  }
}
```

### **2. Request Details** - `/api/v1/debug/requests/{request_id}`
**Purpose**: Complete request analysis with database operations  
**Method**: GET  
**Replaces**: Manual request tracing + database query analysis

```json
{
  "status": "success",
  "request_id": "uuid-123",
  "details": {
    "request": {
      "method": "POST",
      "url": "/api/v1/journal/entries",
      "headers": {"authorization": "Bearer...", "content-type": "application/json"},
      "body": "{\"content\": \"Today was good\"}",
      "user_id": "user-456",
      "ip_address": "192.168.1.1",
      "timestamp": "2025-01-30T10:30:00Z"
    },
    "response": {
      "status_code": 500,
      "response_time_ms": 2500,
      "body": "{\"error\": \"Database timeout\"}",
      "errors": ["Database connection timeout after 2000ms"]
    },
    "database_operations": [
      {
        "operation_type": "SELECT",
        "table": "users",
        "query": "SELECT * FROM users WHERE id = $1",
        "execution_time_ms": 45,
        "rows_affected": 1
      },
      {
        "operation_type": "INSERT",
        "table": "journal_entries",
        "query": "INSERT INTO journal_entries...",
        "execution_time_ms": 2000,
        "error": "Connection timeout"
      }
    ],
    "summary": {
      "total_db_operations": 2,
      "total_db_time_ms": 2045,
      "has_errors": true,
      "performance_score": "error"
    }
  }
}
```

### **3. Filtered Requests** - `/api/v1/debug/requests`
**Purpose**: Get requests by type (errors, slow, all)  
**Method**: GET  
**Parameters**: 
- `filter_type`: "errors", "slow", "all"
- `limit`: Number of requests (default 50)
- `min_time_ms`: Minimum response time for slow filter

### **4. Performance Analysis** - `/api/v1/debug/performance/analysis`
**Purpose**: Response time distribution and performance grading  
**Method**: GET

```json
{
  "status": "success",
  "analysis": {
    "requests_analyzed": 100,
    "response_time_percentiles_ms": {
      "p50": 250,
      "p90": 800,
      "p95": 1200,
      "p99": 2500
    },
    "error_rate": 0.05,
    "average_db_operations": 3.2,
    "recommendations": [
      "95th percentile response time > 1s - investigate slow endpoints",
      "Error rate 5% is acceptable but monitor trends"
    ],
    "performance_grade": "B"
  }
}
```

### **5. Database Statistics** - `/api/v1/debug/database/stats`
**Purpose**: Database operation analysis and optimization recommendations  
**Method**: GET  
**Parameters**: `minutes_back` (default 60)

### **6. Live Debug Stream** - `/api/v1/debug/live/stream`
**Purpose**: Real-time monitoring data  
**Method**: GET  
**Use for**: Live debugging sessions

---

## üîß **AUTOMATED ISSUE DETECTION**

The middleware automatically detects and categorizes issues:

### **Performance Issues**
- **Slow Requests**: >1000ms response time
- **Database Bottlenecks**: >10 DB operations per request
- **High Error Rates**: >5% of requests failing

### **Error Patterns**
- **Authentication Failures**: 401/403 responses
- **CORS Issues**: Origin header problems
- **Database Timeouts**: Connection/query timeouts
- **Import Errors**: Missing function/module imports

### **Automatic Recommendations**
- Database indexing suggestions
- Performance optimization hints
- Error resolution steps
- Configuration fixes

---

## ü§ñ **AI WORKFLOW - MANDATORY FOR ALL DEBUGGING**

### **üö® CRITICAL: Use This Process for ALL User Issues**

#### **Step 1: Get Complete System Overview** (1 tool call)
```bash
GET /api/v1/debug/summary
```
**This replaces:** Railway logs + endpoint testing + CORS verification + environment checking

#### **Step 2: Focus on Issues Found** (1 tool call)
```bash
# If errors found:
GET /api/v1/debug/requests?filter_type=errors

# If performance issues:
GET /api/v1/debug/requests?filter_type=slow

# If database issues:
GET /api/v1/debug/database/stats
```

#### **Step 3: Deep Dive if Needed** (1 tool call)
```bash
# For specific problematic request:
GET /api/v1/debug/requests/{request_id}
```

**Total:** 1-3 tool calls instead of 10-15

### **üéØ When to Use Middleware vs Manual Investigation**

#### **‚úÖ USE MIDDLEWARE DEBUG FOR:**
- User reports errors, slow performance, or login issues
- Authentication problems
- Database performance issues  
- CORS errors
- API endpoint problems
- Response time investigations
- Any operational issue

#### **‚ùå ONLY USE MANUAL INVESTIGATION FOR:**
- Initial project setup
- New feature architecture planning
- Configuration file creation (first time)
- Code review and refactoring

---

## üìä **DEBUGGING DATA ADVANTAGES**

### **Structured Data vs Log Parsing**
- **Old**: Parse unstructured Railway logs
- **New**: Get JSON data ready for AI analysis

### **Request Correlation**
- **Old**: Guess which log entries relate to user's issue
- **New**: Track complete request lifecycle with unique IDs

### **Performance Context**
- **Old**: Manual timing and database query counting
- **New**: Automatic performance scoring and recommendations

### **Error Context**
- **Old**: Error message without request context
- **New**: Complete request/response/database context for every error

---

## üèÜ **SUCCESS METRICS**

### **Tool Call Reduction**
- **Target**: 80% reduction in debugging tool calls
- **From**: 10-15 calls per investigation
- **To**: 1-3 calls per investigation

### **Debug Time Reduction**
- **Target**: 70% faster issue resolution
- **From**: 10-15 minutes of investigation
- **To**: 2-3 minutes with immediate context

### **Information Quality**
- **Complete request context** instead of partial log fragments
- **Automatic performance scoring** instead of manual analysis
- **Database operation tracking** instead of guesswork
- **AI-ready structured data** instead of log parsing

---

## üîß **INTEGRATION WITH EXISTING SYSTEMS**

### **Backend Integration**
- Middleware automatically captures all FastAPI requests
- No code changes needed for existing endpoints
- Automatic database operation tracking
- Error context preservation

### **Frontend Integration**
- All requests get debug headers (X-Request-ID, X-Response-Time)
- Performance data available in browser dev tools
- Error correlation with backend debug data

### **Railway Integration**
- Complements Railway logs with structured data
- Performance data not available in Railway logs
- Request correlation across log entries
- Database operation visibility

---

## üìã **MAINTENANCE AND OPTIMIZATION**

### **Data Retention**
- In-memory store: 1000 recent requests
- Automatic cleanup of old data
- Performance impact: <1% overhead

### **Memory Management**
- Estimated usage: ~3MB for 1000 requests
- Automatic garbage collection
- Configurable retention limits

### **Performance Impact**
- Middleware overhead: <5ms per request
- Benefits far outweigh costs
- Critical for debugging complex issues

---

## üéØ **NEXT STEPS FOR AI ASSISTANTS**

1. **Always start with debug summary** before manual investigation
2. **Use structured data** instead of parsing logs
3. **Follow performance recommendations** from middleware
4. **Document new patterns** in middleware detection
5. **Update this guide** when new debugging patterns emerge

**Remember**: This system transforms debugging from investigation to analysis. Use it first, always. 